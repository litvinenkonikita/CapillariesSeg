digraph {
	graph [size="249.75,249.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3207777947696 [label="
 (1, 2, 1024, 1024)" fillcolor=darkolivegreen1]
	3207778596608 -> 3207778322288 [dir=none]
	3207778322288 [label="input
 (1, 64, 1024, 1024)" fillcolor=orange]
	3207778596608 -> 3207778247728 [dir=none]
	3207778247728 [label="weight
 (2, 64, 1, 1)" fillcolor=orange]
	3207778596608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (2,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778595696 -> 3207778596608
	3207778595696 -> 3207778156848 [dir=none]
	3207778156848 [label="result
 (1, 64, 1024, 1024)" fillcolor=orange]
	3207778595696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778596320 -> 3207778595696
	3207778596320 -> 3207778322608 [dir=none]
	3207778322608 [label="input
 (1, 192, 1024, 1024)" fillcolor=orange]
	3207778596320 -> 3207778248528 [dir=none]
	3207778248528 [label="weight
 (64, 192, 3, 3)" fillcolor=orange]
	3207778596320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778595024 -> 3207778596320
	3207778595024 [label="CatBackward0
------------
dim: 1"]
	3207778594400 -> 3207778595024
	3207778594400 [label="UpsampleBilinear2DBackward0
----------------------------------
align_corners :               True
output_size   :       (1024, 1024)
scales_h      :                2.0
scales_w      :                2.0
self_sym_sizes: (1, 128, 512, 512)"]
	3207778594112 -> 3207778594400
	3207778594112 -> 3207625469248 [dir=none]
	3207625469248 [label="result
 (1, 128, 512, 512)" fillcolor=orange]
	3207778594112 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778593824 -> 3207778594112
	3207778593824 -> 3207778321248 [dir=none]
	3207778321248 [label="input
 (1, 320, 512, 512)" fillcolor=orange]
	3207778593824 -> 3207778250448 [dir=none]
	3207778250448 [label="weight
 (128, 320, 3, 3)" fillcolor=orange]
	3207778593824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (128,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778593488 -> 3207778593824
	3207778593488 [label="CatBackward0
------------
dim: 1"]
	3207778592864 -> 3207778593488
	3207778592864 [label="UpsampleBilinear2DBackward0
----------------------------------
align_corners :               True
output_size   :         (512, 512)
scales_h      :                2.0
scales_w      :                2.0
self_sym_sizes: (1, 256, 256, 256)"]
	3207778591136 -> 3207778592864
	3207778591136 -> 3207778167568 [dir=none]
	3207778167568 [label="result
 (1, 256, 256, 256)" fillcolor=orange]
	3207778591136 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778591904 -> 3207778591136
	3207778591904 -> 3207778321888 [dir=none]
	3207778321888 [label="input
 (1, 320, 256, 256)" fillcolor=orange]
	3207778591904 -> 3207778250928 [dir=none]
	3207778250928 [label="weight
 (256, 320, 3, 3)" fillcolor=orange]
	3207778591904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778590512 -> 3207778591904
	3207778590512 [label="CatBackward0
------------
dim: 1"]
	3207778589888 -> 3207778590512
	3207778589888 [label="UpsampleBilinear2DBackward0
----------------------------------
align_corners :               True
output_size   :         (256, 256)
scales_h      :                2.0
scales_w      :                2.0
self_sym_sizes: (1, 256, 128, 128)"]
	3207778590704 -> 3207778589888
	3207778590704 -> 3207778170288 [dir=none]
	3207778170288 [label="result
 (1, 256, 128, 128)" fillcolor=orange]
	3207778590704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778590368 -> 3207778590704
	3207778590368 -> 3207778320528 [dir=none]
	3207778320528 [label="input
 (1, 640, 128, 128)" fillcolor=orange]
	3207778590368 -> 3207778251568 [dir=none]
	3207778251568 [label="weight
 (256, 640, 3, 3)" fillcolor=orange]
	3207778590368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778590080 -> 3207778590368
	3207778590080 [label="CatBackward0
------------
dim: 1"]
	3207778589504 -> 3207778590080
	3207778589504 [label="UpsampleBilinear2DBackward0
--------------------------------
align_corners :             True
output_size   :       (128, 128)
scales_h      :              2.0
scales_w      :              2.0
self_sym_sizes: (1, 512, 64, 64)"]
	3207778588832 -> 3207778589504
	3207778588832 -> 3207778160448 [dir=none]
	3207778160448 [label="result
 (1, 512, 64, 64)" fillcolor=orange]
	3207778588832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778588496 -> 3207778588832
	3207778588496 -> 3207778321088 [dir=none]
	3207778321088 [label="input
 (1, 768, 64, 64)" fillcolor=orange]
	3207778588496 -> 3207778252048 [dir=none]
	3207778252048 [label="weight
 (512, 768, 3, 3)" fillcolor=orange]
	3207778588496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (512,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778588208 -> 3207778588496
	3207778588208 [label="CatBackward0
------------
dim: 1"]
	3207778587584 -> 3207778588208
	3207778587584 [label="UpsampleBilinear2DBackward0
--------------------------------
align_corners :             True
output_size   :         (64, 64)
scales_h      :              2.0
scales_w      :              2.0
self_sym_sizes: (1, 512, 32, 32)"]
	3207778587296 -> 3207778587584
	3207778587296 -> 3207778165168 [dir=none]
	3207778165168 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778587296 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778587008 -> 3207778587296
	3207778587008 -> 3207778321808 [dir=none]
	3207778321808 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778587008 -> 3207778252528 [dir=none]
	3207778252528 [label="weight
 (512, 512, 1, 1)" fillcolor=orange]
	3207778587008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (512,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778586672 -> 3207778587008
	3207778586672 -> 3207778171168 [dir=none]
	3207778171168 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778586672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778586048 -> 3207778586672
	3207778586048 [label="AddBackward0
------------
alpha: 1"]
	3207778585760 -> 3207778586048
	3207778585760 -> 3207778321728 [dir=none]
	3207778321728 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778585760 -> 3207778172208 [dir=none]
	3207778172208 [label="result1
 (512)" fillcolor=orange]
	3207778585760 -> 3207778166688 [dir=none]
	3207778166688 [label="result2
 (512)" fillcolor=orange]
	3207778585760 -> 3207778164368 [dir=none]
	3207778164368 [label="result3
 (0)" fillcolor=orange]
	3207778585760 -> 3207778302240 [dir=none]
	3207778302240 [label="running_mean
 (512)" fillcolor=orange]
	3207778585760 -> 3207778301440 [dir=none]
	3207778301440 [label="running_var
 (512)" fillcolor=orange]
	3207778585760 -> 3207777955536 [dir=none]
	3207777955536 [label="weight
 (512)" fillcolor=orange]
	3207778585760 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778585088 -> 3207778585760
	3207778585088 -> 3207778320448 [dir=none]
	3207778320448 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778585088 -> 3207777955616 [dir=none]
	3207777955616 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3207778585088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778584464 -> 3207778585088
	3207778584464 -> 3207778161728 [dir=none]
	3207778161728 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778584464 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778584176 -> 3207778584464
	3207778584176 -> 3207778323968 [dir=none]
	3207778323968 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778584176 -> 3207778170768 [dir=none]
	3207778170768 [label="result1
 (512)" fillcolor=orange]
	3207778584176 -> 3207778167168 [dir=none]
	3207778167168 [label="result2
 (512)" fillcolor=orange]
	3207778584176 -> 3207778166768 [dir=none]
	3207778166768 [label="result3
 (0)" fillcolor=orange]
	3207778584176 -> 3207778303040 [dir=none]
	3207778303040 [label="running_mean
 (512)" fillcolor=orange]
	3207778584176 -> 3207778302160 [dir=none]
	3207778302160 [label="running_var
 (512)" fillcolor=orange]
	3207778584176 -> 3207777954896 [dir=none]
	3207777954896 [label="weight
 (512)" fillcolor=orange]
	3207778584176 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778583888 -> 3207778584176
	3207778583888 -> 3207778325408 [dir=none]
	3207778325408 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778583888 -> 3207777954976 [dir=none]
	3207777954976 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3207778583888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778585712 -> 3207778583888
	3207778585712 -> 3207778169168 [dir=none]
	3207778169168 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778585712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778582736 -> 3207778585712
	3207778582736 [label="AddBackward0
------------
alpha: 1"]
	3207778598720 -> 3207778582736
	3207778598720 -> 3207778323568 [dir=none]
	3207778323568 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778598720 -> 3207778164448 [dir=none]
	3207778164448 [label="result1
 (512)" fillcolor=orange]
	3207778598720 -> 3207778166368 [dir=none]
	3207778166368 [label="result2
 (512)" fillcolor=orange]
	3207778598720 -> 3207778164848 [dir=none]
	3207778164848 [label="result3
 (0)" fillcolor=orange]
	3207778598720 -> 3207778294160 [dir=none]
	3207778294160 [label="running_mean
 (512)" fillcolor=orange]
	3207778598720 -> 3207778302720 [dir=none]
	3207778302720 [label="running_var
 (512)" fillcolor=orange]
	3207778598720 -> 3207777954256 [dir=none]
	3207777954256 [label="weight
 (512)" fillcolor=orange]
	3207778598720 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778598864 -> 3207778598720
	3207778598864 -> 3207778327568 [dir=none]
	3207778327568 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778598864 -> 3207777954336 [dir=none]
	3207777954336 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3207778598864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778598144 -> 3207778598864
	3207778598144 -> 3207778168768 [dir=none]
	3207778168768 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778598144 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778598288 -> 3207778598144
	3207778598288 -> 3207778322448 [dir=none]
	3207778322448 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778598288 -> 3207778161328 [dir=none]
	3207778161328 [label="result1
 (512)" fillcolor=orange]
	3207778598288 -> 3207778163248 [dir=none]
	3207778163248 [label="result2
 (512)" fillcolor=orange]
	3207778598288 -> 3207778162528 [dir=none]
	3207778162528 [label="result3
 (0)" fillcolor=orange]
	3207778598288 -> 3207778251808 [dir=none]
	3207778251808 [label="running_mean
 (512)" fillcolor=orange]
	3207778598288 -> 3207778303600 [dir=none]
	3207778303600 [label="running_var
 (512)" fillcolor=orange]
	3207778598288 -> 3207777953616 [dir=none]
	3207777953616 [label="weight
 (512)" fillcolor=orange]
	3207778598288 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778597856 -> 3207778598288
	3207778597856 -> 3207778326208 [dir=none]
	3207778326208 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778597856 -> 3207777953696 [dir=none]
	3207777953696 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3207778597856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778598048 -> 3207778597856
	3207778598048 -> 3207778165248 [dir=none]
	3207778165248 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778598048 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778597664 -> 3207778598048
	3207778597664 [label="AddBackward0
------------
alpha: 1"]
	3207778597280 -> 3207778597664
	3207778597280 -> 3207778325808 [dir=none]
	3207778325808 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778597280 -> 3207778159328 [dir=none]
	3207778159328 [label="result1
 (512)" fillcolor=orange]
	3207778597280 -> 3207778160928 [dir=none]
	3207778160928 [label="result2
 (512)" fillcolor=orange]
	3207778597280 -> 3207778160528 [dir=none]
	3207778160528 [label="result3
 (0)" fillcolor=orange]
	3207778597280 -> 3207778239088 [dir=none]
	3207778239088 [label="running_mean
 (512)" fillcolor=orange]
	3207778597280 -> 3207778254288 [dir=none]
	3207778254288 [label="running_var
 (512)" fillcolor=orange]
	3207778597280 -> 3207777953056 [dir=none]
	3207777953056 [label="weight
 (512)" fillcolor=orange]
	3207778597280 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778596560 -> 3207778597280
	3207778596560 -> 3207778329408 [dir=none]
	3207778329408 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778596560 -> 3207777953136 [dir=none]
	3207777953136 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3207778596560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778596080 -> 3207778596560
	3207778596080 -> 3207778157728 [dir=none]
	3207778157728 [label="result
 (1, 512, 32, 32)" fillcolor=orange]
	3207778596080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778596176 -> 3207778596080
	3207778596176 -> 3207778332368 [dir=none]
	3207778332368 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778596176 -> 3207778158528 [dir=none]
	3207778158528 [label="result1
 (512)" fillcolor=orange]
	3207778596176 -> 3207778159728 [dir=none]
	3207778159728 [label="result2
 (512)" fillcolor=orange]
	3207778596176 -> 3207778158928 [dir=none]
	3207778158928 [label="result3
 (0)" fillcolor=orange]
	3207778596176 -> 3207778239488 [dir=none]
	3207778239488 [label="running_mean
 (512)" fillcolor=orange]
	3207778596176 -> 3207778238768 [dir=none]
	3207778238768 [label="running_var
 (512)" fillcolor=orange]
	3207778596176 -> 3207777952416 [dir=none]
	3207777952416 [label="weight
 (512)" fillcolor=orange]
	3207778596176 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778595744 -> 3207778596176
	3207778595744 -> 3207778328048 [dir=none]
	3207778328048 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778595744 -> 3207777952496 [dir=none]
	3207777952496 [label="weight
 (512, 256, 3, 3)" fillcolor=orange]
	3207778595744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778596032 -> 3207778595744
	3207778596032 -> 3207778157328 [dir=none]
	3207778157328 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778596032 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778595312 -> 3207778596032
	3207778595312 [label="AddBackward0
------------
alpha: 1"]
	3207778595168 -> 3207778595312
	3207778595168 -> 3207778327648 [dir=none]
	3207778327648 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778595168 -> 3207778169088 [dir=none]
	3207778169088 [label="result1
 (256)" fillcolor=orange]
	3207778595168 -> 3207778157488 [dir=none]
	3207778157488 [label="result2
 (256)" fillcolor=orange]
	3207778595168 -> 3207778156928 [dir=none]
	3207778156928 [label="result3
 (0)" fillcolor=orange]
	3207778595168 -> 3207778240208 [dir=none]
	3207778240208 [label="running_mean
 (256)" fillcolor=orange]
	3207778595168 -> 3207778239408 [dir=none]
	3207778239408 [label="running_var
 (256)" fillcolor=orange]
	3207778595168 -> 3207777951056 [dir=none]
	3207777951056 [label="weight
 (256)" fillcolor=orange]
	3207778595168 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778595408 -> 3207778595168
	3207778595408 -> 3207778334528 [dir=none]
	3207778334528 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778595408 -> 3207777951136 [dir=none]
	3207777951136 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778595408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778594496 -> 3207778595408
	3207778594496 -> 3207778156608 [dir=none]
	3207778156608 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778594496 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778594208 -> 3207778594496
	3207778594208 -> 3207778334928 [dir=none]
	3207778334928 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778594208 -> 3207778156688 [dir=none]
	3207778156688 [label="result1
 (256)" fillcolor=orange]
	3207778594208 -> 3207778158208 [dir=none]
	3207778158208 [label="result2
 (256)" fillcolor=orange]
	3207778594208 -> 3207778157008 [dir=none]
	3207778157008 [label="result3
 (0)" fillcolor=orange]
	3207778594208 -> 3207778240768 [dir=none]
	3207778240768 [label="running_mean
 (256)" fillcolor=orange]
	3207778594208 -> 3207778239888 [dir=none]
	3207778239888 [label="running_var
 (256)" fillcolor=orange]
	3207778594208 -> 3207777950416 [dir=none]
	3207777950416 [label="weight
 (256)" fillcolor=orange]
	3207778594208 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778594352 -> 3207778594208
	3207778594352 -> 3207778333168 [dir=none]
	3207778333168 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778594352 -> 3207777950496 [dir=none]
	3207777950496 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778594352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778595120 -> 3207778594352
	3207778595120 -> 3207778157088 [dir=none]
	3207778157088 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778595120 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778593584 -> 3207778595120
	3207778593584 [label="AddBackward0
------------
alpha: 1"]
	3207778593728 -> 3207778593584
	3207778593728 -> 3207778332768 [dir=none]
	3207778332768 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778593728 -> 3207778157568 [dir=none]
	3207778157568 [label="result1
 (256)" fillcolor=orange]
	3207778593728 -> 3207778159008 [dir=none]
	3207778159008 [label="result2
 (256)" fillcolor=orange]
	3207778593728 -> 3207778157888 [dir=none]
	3207778157888 [label="result3
 (0)" fillcolor=orange]
	3207778593728 -> 3207778241408 [dir=none]
	3207778241408 [label="running_mean
 (256)" fillcolor=orange]
	3207778593728 -> 3207778240688 [dir=none]
	3207778240688 [label="running_var
 (256)" fillcolor=orange]
	3207778593728 -> 3207777949776 [dir=none]
	3207777949776 [label="weight
 (256)" fillcolor=orange]
	3207778593728 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778593296 -> 3207778593728
	3207778593296 -> 3207778336608 [dir=none]
	3207778336608 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778593296 -> 3207777949856 [dir=none]
	3207777949856 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778593296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778593104 -> 3207778593296
	3207778593104 -> 3207778157968 [dir=none]
	3207778157968 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778593104 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778592624 -> 3207778593104
	3207778592624 -> 3207778336288 [dir=none]
	3207778336288 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778592624 -> 3207778158288 [dir=none]
	3207778158288 [label="result1
 (256)" fillcolor=orange]
	3207778592624 -> 3207778159888 [dir=none]
	3207778159888 [label="result2
 (256)" fillcolor=orange]
	3207778592624 -> 3207778158608 [dir=none]
	3207778158608 [label="result3
 (0)" fillcolor=orange]
	3207778592624 -> 3207778241888 [dir=none]
	3207778241888 [label="running_mean
 (256)" fillcolor=orange]
	3207778592624 -> 3207778241168 [dir=none]
	3207778241168 [label="running_var
 (256)" fillcolor=orange]
	3207778592624 -> 3207777949136 [dir=none]
	3207777949136 [label="weight
 (256)" fillcolor=orange]
	3207778592624 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778592720 -> 3207778592624
	3207778592720 -> 3207778335968 [dir=none]
	3207778335968 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778592720 -> 3207777949216 [dir=none]
	3207777949216 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778592720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778594160 -> 3207778592720
	3207778594160 -> 3207778158688 [dir=none]
	3207778158688 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778594160 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778592000 -> 3207778594160
	3207778592000 [label="AddBackward0
------------
alpha: 1"]
	3207778592096 -> 3207778592000
	3207778592096 -> 3207778326928 [dir=none]
	3207778326928 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778592096 -> 3207778159088 [dir=none]
	3207778159088 [label="result1
 (256)" fillcolor=orange]
	3207778592096 -> 3207778160608 [dir=none]
	3207778160608 [label="result2
 (256)" fillcolor=orange]
	3207778592096 -> 3207778159488 [dir=none]
	3207778159488 [label="result3
 (0)" fillcolor=orange]
	3207778592096 -> 3207778242688 [dir=none]
	3207778242688 [label="running_mean
 (256)" fillcolor=orange]
	3207778592096 -> 3207778241808 [dir=none]
	3207778241808 [label="running_var
 (256)" fillcolor=orange]
	3207778592096 -> 3207777948496 [dir=none]
	3207777948496 [label="weight
 (256)" fillcolor=orange]
	3207778592096 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778591856 -> 3207778592096
	3207778591856 -> 3207778322848 [dir=none]
	3207778322848 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778591856 -> 3207777948576 [dir=none]
	3207777948576 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778591856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778591424 -> 3207778591856
	3207778591424 -> 3207778159568 [dir=none]
	3207778159568 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778591424 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778591664 -> 3207778591424
	3207778591664 -> 3207778323168 [dir=none]
	3207778323168 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778591664 -> 3207778159968 [dir=none]
	3207778159968 [label="result1
 (256)" fillcolor=orange]
	3207778591664 -> 3207778161488 [dir=none]
	3207778161488 [label="result2
 (256)" fillcolor=orange]
	3207778591664 -> 3207778160208 [dir=none]
	3207778160208 [label="result3
 (0)" fillcolor=orange]
	3207778591664 -> 3207778243168 [dir=none]
	3207778243168 [label="running_mean
 (256)" fillcolor=orange]
	3207778591664 -> 3207778242288 [dir=none]
	3207778242288 [label="running_var
 (256)" fillcolor=orange]
	3207778591664 -> 3207777947856 [dir=none]
	3207777947856 [label="weight
 (256)" fillcolor=orange]
	3207778591664 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778591184 -> 3207778591664
	3207778591184 -> 3207778326128 [dir=none]
	3207778326128 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778591184 -> 3207777947936 [dir=none]
	3207777947936 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778591184 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778592048 -> 3207778591184
	3207778592048 -> 3207778160288 [dir=none]
	3207778160288 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778592048 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778591040 -> 3207778592048
	3207778591040 [label="AddBackward0
------------
alpha: 1"]
	3207778590560 -> 3207778591040
	3207778590560 -> 3207778320688 [dir=none]
	3207778320688 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778590560 -> 3207778160688 [dir=none]
	3207778160688 [label="result1
 (256)" fillcolor=orange]
	3207778590560 -> 3207778161888 [dir=none]
	3207778161888 [label="result2
 (256)" fillcolor=orange]
	3207778590560 -> 3207778161008 [dir=none]
	3207778161008 [label="result3
 (0)" fillcolor=orange]
	3207778590560 -> 3207778243808 [dir=none]
	3207778243808 [label="running_mean
 (256)" fillcolor=orange]
	3207778590560 -> 3207778243088 [dir=none]
	3207778243088 [label="running_var
 (256)" fillcolor=orange]
	3207778590560 -> 3207777947216 [dir=none]
	3207777947216 [label="weight
 (256)" fillcolor=orange]
	3207778590560 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778590176 -> 3207778590560
	3207778590176 -> 3207778322128 [dir=none]
	3207778322128 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778590176 -> 3207777947296 [dir=none]
	3207777947296 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778590176 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778589984 -> 3207778590176
	3207778589984 -> 3207778161088 [dir=none]
	3207778161088 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778589984 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778584320 -> 3207778589984
	3207778584320 -> 3207778325328 [dir=none]
	3207778325328 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778584320 -> 3207778161968 [dir=none]
	3207778161968 [label="result1
 (256)" fillcolor=orange]
	3207778584320 -> 3207778162608 [dir=none]
	3207778162608 [label="result2
 (256)" fillcolor=orange]
	3207778584320 -> 3207778162688 [dir=none]
	3207778162688 [label="result3
 (0)" fillcolor=orange]
	3207778584320 -> 3207778244288 [dir=none]
	3207778244288 [label="running_mean
 (256)" fillcolor=orange]
	3207778584320 -> 3207778243488 [dir=none]
	3207778243488 [label="running_var
 (256)" fillcolor=orange]
	3207778584320 -> 3207777946576 [dir=none]
	3207777946576 [label="weight
 (256)" fillcolor=orange]
	3207778584320 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778589600 -> 3207778584320
	3207778589600 -> 3207778334448 [dir=none]
	3207778334448 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778589600 -> 3207777946656 [dir=none]
	3207777946656 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778589600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778590608 -> 3207778589600
	3207778590608 -> 3207778161568 [dir=none]
	3207778161568 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778590608 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778588928 -> 3207778590608
	3207778588928 [label="AddBackward0
------------
alpha: 1"]
	3207778588592 -> 3207778588928
	3207778588592 -> 3207778333088 [dir=none]
	3207778333088 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778588592 -> 3207778162288 [dir=none]
	3207778162288 [label="result1
 (256)" fillcolor=orange]
	3207778588592 -> 3207778163408 [dir=none]
	3207778163408 [label="result2
 (256)" fillcolor=orange]
	3207778588592 -> 3207778163488 [dir=none]
	3207778163488 [label="result3
 (0)" fillcolor=orange]
	3207778588592 -> 3207778245248 [dir=none]
	3207778245248 [label="running_mean
 (256)" fillcolor=orange]
	3207778588592 -> 3207778244208 [dir=none]
	3207778244208 [label="running_var
 (256)" fillcolor=orange]
	3207778588592 -> 3207777945936 [dir=none]
	3207777945936 [label="weight
 (256)" fillcolor=orange]
	3207778588592 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778588784 -> 3207778588592
	3207778588784 -> 3207778325008 [dir=none]
	3207778325008 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778588784 -> 3207777946016 [dir=none]
	3207777946016 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778588784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778588352 -> 3207778588784
	3207778588352 -> 3207778162208 [dir=none]
	3207778162208 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778588352 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778588112 -> 3207778588352
	3207778588112 -> 3207777946896 [dir=none]
	3207777946896 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778588112 -> 3207778163008 [dir=none]
	3207778163008 [label="result1
 (256)" fillcolor=orange]
	3207778588112 -> 3207778164128 [dir=none]
	3207778164128 [label="result2
 (256)" fillcolor=orange]
	3207778588112 -> 3207778164208 [dir=none]
	3207778164208 [label="result3
 (0)" fillcolor=orange]
	3207778588112 -> 3207778245008 [dir=none]
	3207778245008 [label="running_mean
 (256)" fillcolor=orange]
	3207778588112 -> 3207778244688 [dir=none]
	3207778244688 [label="running_var
 (256)" fillcolor=orange]
	3207778588112 -> 3207777945296 [dir=none]
	3207777945296 [label="weight
 (256)" fillcolor=orange]
	3207778588112 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778587824 -> 3207778588112
	3207778587824 -> 3207777956256 [dir=none]
	3207777956256 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778587824 -> 3207777945376 [dir=none]
	3207777945376 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778587824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778588976 -> 3207778587824
	3207778588976 -> 3207778162928 [dir=none]
	3207778162928 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778588976 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778587536 -> 3207778588976
	3207778587536 [label="AddBackward0
------------
alpha: 1"]
	3207778587200 -> 3207778587536
	3207778587200 -> 3207777944416 [dir=none]
	3207777944416 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778587200 -> 3207778163888 [dir=none]
	3207778163888 [label="result1
 (256)" fillcolor=orange]
	3207778587200 -> 3207778164928 [dir=none]
	3207778164928 [label="result2
 (256)" fillcolor=orange]
	3207778587200 -> 3207778165008 [dir=none]
	3207778165008 [label="result3
 (0)" fillcolor=orange]
	3207778587200 -> 3207674262000 [dir=none]
	3207674262000 [label="running_mean
 (256)" fillcolor=orange]
	3207778587200 -> 3207778245648 [dir=none]
	3207778245648 [label="running_var
 (256)" fillcolor=orange]
	3207778587200 -> 3207777944736 [dir=none]
	3207777944736 [label="weight
 (256)" fillcolor=orange]
	3207778587200 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778586720 -> 3207778587200
	3207778586720 -> 3207777943696 [dir=none]
	3207777943696 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778586720 -> 3207777944816 [dir=none]
	3207777944816 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3207778586720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778586816 -> 3207778586720
	3207778586816 -> 3207778163808 [dir=none]
	3207778163808 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778586816 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778586480 -> 3207778586816
	3207778586480 -> 3207777955376 [dir=none]
	3207777955376 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778586480 -> 3207778164608 [dir=none]
	3207778164608 [label="result1
 (256)" fillcolor=orange]
	3207778586480 -> 3207778165488 [dir=none]
	3207778165488 [label="result2
 (256)" fillcolor=orange]
	3207778586480 -> 3207778161248 [dir=none]
	3207778161248 [label="result3
 (0)" fillcolor=orange]
	3207778586480 -> 3207674265120 [dir=none]
	3207674265120 [label="running_mean
 (256)" fillcolor=orange]
	3207778586480 -> 3207778246128 [dir=none]
	3207778246128 [label="running_var
 (256)" fillcolor=orange]
	3207778586480 -> 3207777944096 [dir=none]
	3207777944096 [label="weight
 (256)" fillcolor=orange]
	3207778586480 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778586144 -> 3207778586480
	3207778586144 -> 3207777955776 [dir=none]
	3207777955776 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778586144 -> 3207777944176 [dir=none]
	3207777944176 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	3207778586144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778585952 -> 3207778586144
	3207778585952 -> 3207778160128 [dir=none]
	3207778160128 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778585952 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778585472 -> 3207778585952
	3207778585472 [label="AddBackward0
------------
alpha: 1"]
	3207778585616 -> 3207778585472
	3207778585616 -> 3207777955936 [dir=none]
	3207777955936 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778585616 -> 3207778165808 [dir=none]
	3207778165808 [label="result1
 (128)" fillcolor=orange]
	3207778585616 -> 3207778164528 [dir=none]
	3207778164528 [label="result2
 (128)" fillcolor=orange]
	3207778585616 -> 3207778166128 [dir=none]
	3207778166128 [label="result3
 (0)" fillcolor=orange]
	3207778585616 -> 3207674264480 [dir=none]
	3207674264480 [label="running_mean
 (128)" fillcolor=orange]
	3207778585616 -> 3207674264560 [dir=none]
	3207674264560 [label="running_var
 (128)" fillcolor=orange]
	3207778585616 -> 3207674264720 [dir=none]
	3207674264720 [label="weight
 (128)" fillcolor=orange]
	3207778585616 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778585328 -> 3207778585616
	3207778585328 -> 3207777954736 [dir=none]
	3207777954736 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778585328 -> 3207674264800 [dir=none]
	3207674264800 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778585328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778584896 -> 3207778585328
	3207778584896 -> 3207778166048 [dir=none]
	3207778166048 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778584896 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778584944 -> 3207778584896
	3207778584944 -> 3207777954656 [dir=none]
	3207777954656 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778584944 -> 3207778166448 [dir=none]
	3207778166448 [label="result1
 (128)" fillcolor=orange]
	3207778584944 -> 3207778165408 [dir=none]
	3207778165408 [label="result2
 (128)" fillcolor=orange]
	3207778584944 -> 3207778166848 [dir=none]
	3207778166848 [label="result3
 (0)" fillcolor=orange]
	3207778584944 -> 3207674263840 [dir=none]
	3207674263840 [label="running_mean
 (128)" fillcolor=orange]
	3207778584944 -> 3207674263920 [dir=none]
	3207674263920 [label="running_var
 (128)" fillcolor=orange]
	3207778584944 -> 3207674264080 [dir=none]
	3207674264080 [label="weight
 (128)" fillcolor=orange]
	3207778584944 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778584560 -> 3207778584944
	3207778584560 -> 3207777955136 [dir=none]
	3207777955136 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778584560 -> 3207674264160 [dir=none]
	3207674264160 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778584560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778585520 -> 3207778584560
	3207778585520 -> 3207778166528 [dir=none]
	3207778166528 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778585520 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778584080 -> 3207778585520
	3207778584080 [label="AddBackward0
------------
alpha: 1"]
	3207778583984 -> 3207778584080
	3207778583984 -> 3207777955296 [dir=none]
	3207777955296 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778583984 -> 3207778167328 [dir=none]
	3207778167328 [label="result1
 (128)" fillcolor=orange]
	3207778583984 -> 3207778166928 [dir=none]
	3207778166928 [label="result2
 (128)" fillcolor=orange]
	3207778583984 -> 3207778167728 [dir=none]
	3207778167728 [label="result3
 (0)" fillcolor=orange]
	3207778583984 -> 3207674263200 [dir=none]
	3207674263200 [label="running_mean
 (128)" fillcolor=orange]
	3207778583984 -> 3207674263280 [dir=none]
	3207674263280 [label="running_var
 (128)" fillcolor=orange]
	3207778583984 -> 3207674263440 [dir=none]
	3207674263440 [label="weight
 (128)" fillcolor=orange]
	3207778583984 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778583744 -> 3207778583984
	3207778583744 -> 3207777954016 [dir=none]
	3207777954016 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778583744 -> 3207674263520 [dir=none]
	3207674263520 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778583744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778582832 -> 3207778583744
	3207778582832 -> 3207778167408 [dir=none]
	3207778167408 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778582832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778582640 -> 3207778582832
	3207778582640 -> 3207777953856 [dir=none]
	3207777953856 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778582640 -> 3207778168928 [dir=none]
	3207778168928 [label="result1
 (128)" fillcolor=orange]
	3207778582640 -> 3207778167808 [dir=none]
	3207778167808 [label="result2
 (128)" fillcolor=orange]
	3207778582640 -> 3207778168128 [dir=none]
	3207778168128 [label="result3
 (0)" fillcolor=orange]
	3207778582640 -> 3207674261440 [dir=none]
	3207674261440 [label="running_mean
 (128)" fillcolor=orange]
	3207778582640 -> 3207674262640 [dir=none]
	3207674262640 [label="running_var
 (128)" fillcolor=orange]
	3207778582640 -> 3207674262800 [dir=none]
	3207674262800 [label="weight
 (128)" fillcolor=orange]
	3207778582640 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778548320 -> 3207778582640
	3207778548320 -> 3207777954096 [dir=none]
	3207777954096 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778548320 -> 3207674262880 [dir=none]
	3207674262880 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778548320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778583936 -> 3207778548320
	3207778583936 -> 3207778168848 [dir=none]
	3207778168848 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778583936 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778548464 -> 3207778583936
	3207778548464 [label="AddBackward0
------------
alpha: 1"]
	3207778547072 -> 3207778548464
	3207778547072 -> 3207777954496 [dir=none]
	3207777954496 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778547072 -> 3207778169808 [dir=none]
	3207778169808 [label="result1
 (128)" fillcolor=orange]
	3207778547072 -> 3207778168048 [dir=none]
	3207778168048 [label="result2
 (128)" fillcolor=orange]
	3207778547072 -> 3207778168528 [dir=none]
	3207778168528 [label="result3
 (0)" fillcolor=orange]
	3207778547072 -> 3206844141776 [dir=none]
	3206844141776 [label="running_mean
 (128)" fillcolor=orange]
	3207778547072 -> 3207674261920 [dir=none]
	3207674261920 [label="running_var
 (128)" fillcolor=orange]
	3207778547072 -> 3207674262160 [dir=none]
	3207674262160 [label="weight
 (128)" fillcolor=orange]
	3207778547072 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778547888 -> 3207778547072
	3207778547888 -> 3207777953456 [dir=none]
	3207777953456 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778547888 -> 3207674262240 [dir=none]
	3207674262240 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778547888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778547264 -> 3207778547888
	3207778547264 -> 3207778169728 [dir=none]
	3207778169728 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778547264 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778546592 -> 3207778547264
	3207778546592 -> 3207777952176 [dir=none]
	3207777952176 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778546592 -> 3207778170528 [dir=none]
	3207778170528 [label="result1
 (128)" fillcolor=orange]
	3207778546592 -> 3207778168448 [dir=none]
	3207778168448 [label="result2
 (128)" fillcolor=orange]
	3207778546592 -> 3207778169408 [dir=none]
	3207778169408 [label="result3
 (0)" fillcolor=orange]
	3207778546592 -> 3206844141616 [dir=none]
	3206844141616 [label="running_mean
 (128)" fillcolor=orange]
	3207778546592 -> 3206844146656 [dir=none]
	3206844146656 [label="running_var
 (128)" fillcolor=orange]
	3207778546592 -> 3207674261600 [dir=none]
	3207674261600 [label="weight
 (128)" fillcolor=orange]
	3207778546592 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778545200 -> 3207778546592
	3207778545200 -> 3207777953296 [dir=none]
	3207777953296 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778545200 -> 3207674261680 [dir=none]
	3207674261680 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778545200 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778548512 -> 3207778545200
	3207778548512 -> 3207778170448 [dir=none]
	3207778170448 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778548512 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778545344 -> 3207778548512
	3207778545344 [label="AddBackward0
------------
alpha: 1"]
	3207778543952 -> 3207778545344
	3207778543952 -> 3207777951616 [dir=none]
	3207777951616 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778543952 -> 3207778171328 [dir=none]
	3207778171328 [label="result1
 (128)" fillcolor=orange]
	3207778543952 -> 3207778169328 [dir=none]
	3207778169328 [label="result2
 (128)" fillcolor=orange]
	3207778543952 -> 3207778170128 [dir=none]
	3207778170128 [label="result3
 (0)" fillcolor=orange]
	3207778543952 -> 3206844152016 [dir=none]
	3206844152016 [label="running_mean
 (128)" fillcolor=orange]
	3207778543952 -> 3206844145216 [dir=none]
	3206844145216 [label="running_var
 (128)" fillcolor=orange]
	3207778543952 -> 3206844138816 [dir=none]
	3206844138816 [label="weight
 (128)" fillcolor=orange]
	3207778543952 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778544768 -> 3207778543952
	3207778544768 -> 3207777951936 [dir=none]
	3207777951936 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778544768 -> 3206844138736 [dir=none]
	3206844138736 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3207778544768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778544144 -> 3207778544768
	3207778544144 -> 3207778170848 [dir=none]
	3207778170848 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778544144 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778543472 -> 3207778544144
	3207778543472 -> 3207777949376 [dir=none]
	3207777949376 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778543472 -> 3207778171968 [dir=none]
	3207778171968 [label="result1
 (128)" fillcolor=orange]
	3207778543472 -> 3207778170048 [dir=none]
	3207778170048 [label="result2
 (128)" fillcolor=orange]
	3207778543472 -> 3207778172288 [dir=none]
	3207778172288 [label="result3
 (0)" fillcolor=orange]
	3207778543472 -> 3206844140096 [dir=none]
	3206844140096 [label="running_mean
 (128)" fillcolor=orange]
	3207778543472 -> 3206844139776 [dir=none]
	3206844139776 [label="running_var
 (128)" fillcolor=orange]
	3207778543472 -> 3206844147696 [dir=none]
	3206844147696 [label="weight
 (128)" fillcolor=orange]
	3207778543472 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778542080 -> 3207778543472
	3207778542080 -> 3207777952656 [dir=none]
	3207777952656 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778542080 -> 3206844147616 [dir=none]
	3206844147616 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	3207778542080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778541456 -> 3207778542080
	3207778541456 -> 3207778171888 [dir=none]
	3207778171888 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778541456 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778542272 -> 3207778541456
	3207778542272 [label="AddBackward0
------------
alpha: 1"]
	3207778541936 -> 3207778542272
	3207778541936 -> 3207777952256 [dir=none]
	3207777952256 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778541936 -> 3207778170928 [dir=none]
	3207778170928 [label="result1
 (64)" fillcolor=orange]
	3207778541936 -> 3207778172688 [dir=none]
	3207778172688 [label="result2
 (64)" fillcolor=orange]
	3207778541936 -> 3207778171648 [dir=none]
	3207778171648 [label="result3
 (0)" fillcolor=orange]
	3207778541936 -> 3206844140416 [dir=none]
	3206844140416 [label="running_mean
 (64)" fillcolor=orange]
	3207778541936 -> 3206844140336 [dir=none]
	3206844140336 [label="running_var
 (64)" fillcolor=orange]
	3207778541936 -> 3206844147136 [dir=none]
	3206844147136 [label="weight
 (64)" fillcolor=orange]
	3207778541936 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778540208 -> 3207778541936
	3207778540208 -> 3207777952816 [dir=none]
	3207777952816 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778540208 -> 3206844140256 [dir=none]
	3206844140256 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778540208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778539584 -> 3207778540208
	3207778539584 -> 3207778172608 [dir=none]
	3207778172608 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778539584 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778540400 -> 3207778539584
	3207778540400 -> 3207777952896 [dir=none]
	3207777952896 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778540400 -> 3207778162128 [dir=none]
	3207778162128 [label="result1
 (64)" fillcolor=orange]
	3207778540400 -> 3207778171808 [dir=none]
	3207778171808 [label="result2
 (64)" fillcolor=orange]
	3207778540400 -> 3207778172368 [dir=none]
	3207778172368 [label="result3
 (0)" fillcolor=orange]
	3207778540400 -> 3206844140896 [dir=none]
	3206844140896 [label="running_mean
 (64)" fillcolor=orange]
	3207778540400 -> 3206844140816 [dir=none]
	3206844140816 [label="running_var
 (64)" fillcolor=orange]
	3207778540400 -> 3206844147456 [dir=none]
	3206844147456 [label="weight
 (64)" fillcolor=orange]
	3207778540400 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778540064 -> 3207778540400
	3207778540064 -> 3207777950896 [dir=none]
	3207777950896 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778540064 -> 3206844140576 [dir=none]
	3206844140576 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778540064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778540832 -> 3207778540064
	3207778540832 -> 3207778166288 [dir=none]
	3207778166288 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778540832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778539152 -> 3207778540832
	3207778539152 [label="AddBackward0
------------
alpha: 1"]
	3207778538816 -> 3207778539152
	3207778538816 -> 3207777951296 [dir=none]
	3207777951296 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778538816 -> 3207778172128 [dir=none]
	3207778172128 [label="result1
 (64)" fillcolor=orange]
	3207778538816 -> 3207778168288 [dir=none]
	3207778168288 [label="result2
 (64)" fillcolor=orange]
	3207778538816 -> 3207778162448 [dir=none]
	3207778162448 [label="result3
 (0)" fillcolor=orange]
	3207778538816 -> 3206844141216 [dir=none]
	3206844141216 [label="running_mean
 (64)" fillcolor=orange]
	3207778538816 -> 3206844141136 [dir=none]
	3206844141136 [label="running_var
 (64)" fillcolor=orange]
	3207778538816 -> 3206844147936 [dir=none]
	3206844147936 [label="weight
 (64)" fillcolor=orange]
	3207778538816 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778537088 -> 3207778538816
	3207778537088 -> 3207777951456 [dir=none]
	3207777951456 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778537088 -> 3206844141056 [dir=none]
	3206844141056 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778537088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778536464 -> 3207778537088
	3207778536464 -> 3207667673632 [dir=none]
	3207667673632 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778536464 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778537280 -> 3207778536464
	3207778537280 -> 3207777950256 [dir=none]
	3207777950256 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778537280 -> 3207666755568 [dir=none]
	3207666755568 [label="result1
 (64)" fillcolor=orange]
	3207778537280 -> 3207666755648 [dir=none]
	3207666755648 [label="result2
 (64)" fillcolor=orange]
	3207778537280 -> 3206862512560 [dir=none]
	3206862512560 [label="result3
 (0)" fillcolor=orange]
	3207778537280 -> 3207778246928 [dir=none]
	3207778246928 [label="running_mean
 (64)" fillcolor=orange]
	3207778537280 -> 3207673705984 [dir=none]
	3207673705984 [label="running_var
 (64)" fillcolor=orange]
	3207778537280 -> 3206844148256 [dir=none]
	3206844148256 [label="weight
 (64)" fillcolor=orange]
	3207778537280 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778536944 -> 3207778537280
	3207778536944 -> 3207777950176 [dir=none]
	3207777950176 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778536944 -> 3206844141376 [dir=none]
	3206844141376 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778536944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778537712 -> 3207778536944
	3207778537712 -> 3207641584784 [dir=none]
	3207641584784 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778537712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778536032 -> 3207778537712
	3207778536032 [label="AddBackward0
------------
alpha: 1"]
	3207778535312 -> 3207778536032
	3207778535312 -> 3207777950656 [dir=none]
	3207777950656 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778535312 -> 3207778160848 [dir=none]
	3207778160848 [label="result1
 (64)" fillcolor=orange]
	3207778535312 -> 3207778158448 [dir=none]
	3207778158448 [label="result2
 (64)" fillcolor=orange]
	3207778535312 -> 3207778171488 [dir=none]
	3207778171488 [label="result3
 (0)" fillcolor=orange]
	3207778535312 -> 3207778246528 [dir=none]
	3207778246528 [label="running_mean
 (64)" fillcolor=orange]
	3207778535312 -> 3206844148496 [dir=none]
	3206844148496 [label="running_var
 (64)" fillcolor=orange]
	3207778535312 -> 3206844141536 [dir=none]
	3206844141536 [label="weight
 (64)" fillcolor=orange]
	3207778535312 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778535072 -> 3207778535312
	3207778535072 -> 3207777950816 [dir=none]
	3207777950816 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778535072 -> 3206844141456 [dir=none]
	3206844141456 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778535072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778534112 -> 3207778535072
	3207778534112 -> 3207778170368 [dir=none]
	3207778170368 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778534112 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778533872 -> 3207778534112
	3207778533872 -> 3207777949536 [dir=none]
	3207777949536 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778533872 -> 3207778168688 [dir=none]
	3207778168688 [label="result1
 (64)" fillcolor=orange]
	3207778533872 -> 3207778168368 [dir=none]
	3207778168368 [label="result2
 (64)" fillcolor=orange]
	3207778533872 -> 3207778157248 [dir=none]
	3207778157248 [label="result3
 (0)" fillcolor=orange]
	3207778533872 -> 3207778247008 [dir=none]
	3207778247008 [label="running_mean
 (64)" fillcolor=orange]
	3207778533872 -> 3206844148976 [dir=none]
	3206844148976 [label="running_var
 (64)" fillcolor=orange]
	3207778533872 -> 3206844142016 [dir=none]
	3206844142016 [label="weight
 (64)" fillcolor=orange]
	3207778533872 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778533584 -> 3207778533872
	3207778533584 -> 3207777949616 [dir=none]
	3207777949616 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778533584 -> 3206844141936 [dir=none]
	3206844141936 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778533584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778534592 -> 3207778533584
	3207778534592 -> 3207778167968 [dir=none]
	3207778167968 [label="result1
 (1, 64, 256, 256)" fillcolor=orange]
	3207778534592 -> 3207777950016 [dir=none]
	3207777950016 [label="self
 (1, 64, 512, 512)" fillcolor=orange]
	3207778534592 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	3207778549376 -> 3207778534592
	3207778549376 -> 3207778248048 [dir=none]
	3207778248048 [label="result
 (1, 64, 512, 512)" fillcolor=orange]
	3207778549376 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778549232 -> 3207778549376
	3207778549232 -> 3207777948736 [dir=none]
	3207777948736 [label="input
 (1, 64, 512, 512)" fillcolor=orange]
	3207778549232 -> 3207778245968 [dir=none]
	3207778245968 [label="result1
 (64)" fillcolor=orange]
	3207778549232 -> 3207778245888 [dir=none]
	3207778245888 [label="result2
 (64)" fillcolor=orange]
	3207778549232 -> 3207778242448 [dir=none]
	3207778242448 [label="result3
 (0)" fillcolor=orange]
	3207778549232 -> 3207778247248 [dir=none]
	3207778247248 [label="running_mean
 (64)" fillcolor=orange]
	3207778549232 -> 3206844149216 [dir=none]
	3206844149216 [label="running_var
 (64)" fillcolor=orange]
	3207778549232 -> 3206844142256 [dir=none]
	3206844142256 [label="weight
 (64)" fillcolor=orange]
	3207778549232 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778548896 -> 3207778549232
	3207778548896 -> 3207777946256 [dir=none]
	3207777946256 [label="input
 (1, 3, 1024, 1024)" fillcolor=orange]
	3207778548896 -> 3206844142336 [dir=none]
	3206844142336 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	3207778548896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (3, 3)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778548752 -> 3207778548896
	3206844142336 [label="base_model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	3206844142336 -> 3207778548752
	3207778548752 [label=AccumulateGrad]
	3207778549280 -> 3207778549232
	3206844142256 [label="base_model.bn1.weight
 (64)" fillcolor=lightblue]
	3206844142256 -> 3207778549280
	3207778549280 [label=AccumulateGrad]
	3207778549664 -> 3207778549232
	3206844149136 [label="base_model.bn1.bias
 (64)" fillcolor=lightblue]
	3206844149136 -> 3207778549664
	3207778549664 [label=AccumulateGrad]
	3207778549520 -> 3207778533584
	3206844141936 [label="base_model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844141936 -> 3207778549520
	3207778549520 [label=AccumulateGrad]
	3207778533536 -> 3207778533872
	3206844142016 [label="base_model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	3206844142016 -> 3207778533536
	3207778533536 [label=AccumulateGrad]
	3207778534160 -> 3207778533872
	3206844148816 [label="base_model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	3206844148816 -> 3207778534160
	3207778534160 [label=AccumulateGrad]
	3207778534448 -> 3207778535072
	3206844141456 [label="base_model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844141456 -> 3207778534448
	3207778534448 [label=AccumulateGrad]
	3207778533968 -> 3207778535312
	3206844141536 [label="base_model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	3206844141536 -> 3207778533968
	3207778533968 [label=AccumulateGrad]
	3207778535360 -> 3207778535312
	3206844148656 [label="base_model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	3206844148656 -> 3207778535360
	3207778535360 [label=AccumulateGrad]
	3207778534592 -> 3207778536032
	3207778536320 -> 3207778536944
	3206844141376 [label="base_model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844141376 -> 3207778536320
	3207778536320 [label=AccumulateGrad]
	3207778535840 -> 3207778537280
	3206844148256 [label="base_model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	3206844148256 -> 3207778535840
	3207778535840 [label=AccumulateGrad]
	3207778537568 -> 3207778537280
	3206844141296 [label="base_model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	3206844141296 -> 3207778537568
	3207778537568 [label=AccumulateGrad]
	3207778537904 -> 3207778537088
	3206844141056 [label="base_model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844141056 -> 3207778537904
	3207778537904 [label=AccumulateGrad]
	3207778538528 -> 3207778538816
	3206844147936 [label="base_model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	3206844147936 -> 3207778538528
	3207778538528 [label=AccumulateGrad]
	3207778538480 -> 3207778538816
	3206844140976 [label="base_model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	3206844140976 -> 3207778538480
	3207778538480 [label=AccumulateGrad]
	3207778537712 -> 3207778539152
	3207778539440 -> 3207778540064
	3206844140576 [label="base_model.layer1.2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844140576 -> 3207778539440
	3207778539440 [label=AccumulateGrad]
	3207778538960 -> 3207778540400
	3206844147456 [label="base_model.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	3206844147456 -> 3207778538960
	3207778538960 [label=AccumulateGrad]
	3207778540688 -> 3207778540400
	3206844140496 [label="base_model.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	3206844140496 -> 3207778540688
	3207778540688 [label=AccumulateGrad]
	3207778541024 -> 3207778540208
	3206844140256 [label="base_model.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3206844140256 -> 3207778541024
	3207778541024 [label=AccumulateGrad]
	3207778541648 -> 3207778541936
	3206844147136 [label="base_model.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	3206844147136 -> 3207778541648
	3207778541648 [label=AccumulateGrad]
	3207778541600 -> 3207778541936
	3206844140176 [label="base_model.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	3206844140176 -> 3207778541600
	3207778541600 [label=AccumulateGrad]
	3207778540832 -> 3207778542272
	3207778542896 -> 3207778542080
	3206844147616 [label="base_model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	3206844147616 -> 3207778542896
	3207778542896 [label=AccumulateGrad]
	3207778543520 -> 3207778543472
	3206844147696 [label="base_model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	3206844147696 -> 3207778543520
	3207778543520 [label=AccumulateGrad]
	3207778542704 -> 3207778543472
	3206844140736 [label="base_model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	3206844140736 -> 3207778542704
	3207778542704 [label=AccumulateGrad]
	3207778544096 -> 3207778544768
	3206844138736 [label="base_model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3206844138736 -> 3207778544096
	3207778544096 [label=AccumulateGrad]
	3207778544720 -> 3207778543952
	3206844138816 [label="base_model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	3206844138816 -> 3207778544720
	3207778544720 [label=AccumulateGrad]
	3207778545056 -> 3207778543952
	3207674261200 [label="base_model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	3207674261200 -> 3207778545056
	3207778545056 [label=AccumulateGrad]
	3207778545392 -> 3207778545344
	3207778545392 -> 3207777952096 [dir=none]
	3207777952096 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778545392 -> 3207778246368 [dir=none]
	3207778246368 [label="result1
 (128)" fillcolor=orange]
	3207778545392 -> 3207778252688 [dir=none]
	3207778252688 [label="result2
 (128)" fillcolor=orange]
	3207778545392 -> 3207778245488 [dir=none]
	3207778245488 [label="result3
 (0)" fillcolor=orange]
	3207778545392 -> 3207778246608 [dir=none]
	3207778246608 [label="running_mean
 (128)" fillcolor=orange]
	3207778545392 -> 3206844147296 [dir=none]
	3206844147296 [label="running_var
 (128)" fillcolor=orange]
	3207778545392 -> 3206844146896 [dir=none]
	3206844146896 [label="weight
 (128)" fillcolor=orange]
	3207778545392 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778542848 -> 3207778545392
	3207778542848 -> 3207777952656 [dir=none]
	3207777952656 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778542848 -> 3206844140016 [dir=none]
	3206844140016 [label="weight
 (128, 64, 1, 1)" fillcolor=orange]
	3207778542848 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778541456 -> 3207778542848
	3207778542560 -> 3207778542848
	3206844140016 [label="base_model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	3206844140016 -> 3207778542560
	3207778542560 [label=AccumulateGrad]
	3207778544432 -> 3207778545392
	3206844146896 [label="base_model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	3206844146896 -> 3207778544432
	3207778544432 [label=AccumulateGrad]
	3207778543328 -> 3207778545392
	3206844146816 [label="base_model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	3206844146816 -> 3207778543328
	3207778543328 [label=AccumulateGrad]
	3207778544576 -> 3207778545200
	3207674261680 [label="base_model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674261680 -> 3207778544576
	3207778544576 [label=AccumulateGrad]
	3207778546640 -> 3207778546592
	3207674261600 [label="base_model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	3207674261600 -> 3207778546640
	3207778546640 [label=AccumulateGrad]
	3207778545824 -> 3207778546592
	3207674261760 [label="base_model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	3207674261760 -> 3207778545824
	3207778545824 [label=AccumulateGrad]
	3207778547216 -> 3207778547888
	3207674262240 [label="base_model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674262240 -> 3207778547216
	3207778547216 [label=AccumulateGrad]
	3207778547840 -> 3207778547072
	3207674262160 [label="base_model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	3207674262160 -> 3207778547840
	3207778547840 [label=AccumulateGrad]
	3207778548176 -> 3207778547072
	3207674262320 [label="base_model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	3207674262320 -> 3207778548176
	3207778548176 [label=AccumulateGrad]
	3207778548512 -> 3207778548464
	3207778547696 -> 3207778548320
	3207674262880 [label="base_model.layer2.2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674262880 -> 3207778547696
	3207778547696 [label=AccumulateGrad]
	3207778547120 -> 3207778582640
	3207674262800 [label="base_model.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	3207674262800 -> 3207778547120
	3207778547120 [label=AccumulateGrad]
	3207778549568 -> 3207778582640
	3207674262960 [label="base_model.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	3207674262960 -> 3207778549568
	3207778549568 [label=AccumulateGrad]
	3207778583072 -> 3207778583744
	3207674263520 [label="base_model.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674263520 -> 3207778583072
	3207778583072 [label=AccumulateGrad]
	3207778583648 -> 3207778583984
	3207674263440 [label="base_model.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	3207674263440 -> 3207778583648
	3207778583648 [label=AccumulateGrad]
	3207778583600 -> 3207778583984
	3207674263600 [label="base_model.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	3207674263600 -> 3207778583600
	3207778583600 [label=AccumulateGrad]
	3207778583936 -> 3207778584080
	3207778584368 -> 3207778584560
	3207674264160 [label="base_model.layer2.3.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674264160 -> 3207778584368
	3207778584368 [label=AccumulateGrad]
	3207778584704 -> 3207778584944
	3207674264080 [label="base_model.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	3207674264080 -> 3207778584704
	3207778584704 [label=AccumulateGrad]
	3207778584992 -> 3207778584944
	3207674264240 [label="base_model.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	3207674264240 -> 3207778584992
	3207778584992 [label=AccumulateGrad]
	3207778584848 -> 3207778585328
	3207674264800 [label="base_model.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3207674264800 -> 3207778584848
	3207778584848 [label=AccumulateGrad]
	3207778585568 -> 3207778585616
	3207674264720 [label="base_model.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	3207674264720 -> 3207778585568
	3207778585568 [label=AccumulateGrad]
	3207778585664 -> 3207778585616
	3207674264880 [label="base_model.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	3207674264880 -> 3207778585664
	3207778585664 [label=AccumulateGrad]
	3207778585520 -> 3207778585472
	3207778586192 -> 3207778586144
	3207777944176 [label="base_model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	3207777944176 -> 3207778586192
	3207778586192 [label=AccumulateGrad]
	3207778586096 -> 3207778586480
	3207777944096 [label="base_model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	3207777944096 -> 3207778586096
	3207778586096 [label=AccumulateGrad]
	3207778586576 -> 3207778586480
	3207777944256 [label="base_model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	3207777944256 -> 3207778586576
	3207778586576 [label=AccumulateGrad]
	3207778586912 -> 3207778586720
	3207777944816 [label="base_model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777944816 -> 3207778586912
	3207778586912 [label=AccumulateGrad]
	3207778587104 -> 3207778587200
	3207777944736 [label="base_model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	3207777944736 -> 3207778587104
	3207778587104 [label=AccumulateGrad]
	3207778587056 -> 3207778587200
	3207777944896 [label="base_model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	3207777944896 -> 3207778587056
	3207778587056 [label=AccumulateGrad]
	3207778587440 -> 3207778587536
	3207778587440 -> 3206857766640 [dir=none]
	3206857766640 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778587440 -> 3207778245168 [dir=none]
	3207778245168 [label="result1
 (256)" fillcolor=orange]
	3207778587440 -> 3207778245568 [dir=none]
	3207778245568 [label="result2
 (256)" fillcolor=orange]
	3207778587440 -> 3207778239648 [dir=none]
	3207778239648 [label="result3
 (0)" fillcolor=orange]
	3207778587440 -> 3207778245728 [dir=none]
	3207778245728 [label="running_mean
 (256)" fillcolor=orange]
	3207778587440 -> 3207674265280 [dir=none]
	3207674265280 [label="running_var
 (256)" fillcolor=orange]
	3207778587440 -> 3207674265440 [dir=none]
	3207674265440 [label="weight
 (256)" fillcolor=orange]
	3207778587440 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778586288 -> 3207778587440
	3207778586288 -> 3207777955776 [dir=none]
	3207777955776 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778586288 -> 3207674265360 [dir=none]
	3207674265360 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	3207778586288 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778585952 -> 3207778586288
	3207778585808 -> 3207778586288
	3207674265360 [label="base_model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	3207674265360 -> 3207778585808
	3207778585808 [label=AccumulateGrad]
	3207778586864 -> 3207778587440
	3207674265440 [label="base_model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	3207674265440 -> 3207778586864
	3207778586864 [label=AccumulateGrad]
	3207778586768 -> 3207778587440
	3207674265520 [label="base_model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	3207674265520 -> 3207778586768
	3207778586768 [label=AccumulateGrad]
	3207778587392 -> 3207778587824
	3207777945376 [label="base_model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777945376 -> 3207778587392
	3207778587392 [label=AccumulateGrad]
	3207778588160 -> 3207778588112
	3207777945296 [label="base_model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	3207777945296 -> 3207778588160
	3207778588160 [label=AccumulateGrad]
	3207778587968 -> 3207778588112
	3207777945456 [label="base_model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	3207777945456 -> 3207778587968
	3207778587968 [label=AccumulateGrad]
	3207778588304 -> 3207778588784
	3207777946016 [label="base_model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777946016 -> 3207778588304
	3207778588304 [label=AccumulateGrad]
	3207778588736 -> 3207778588592
	3207777945936 [label="base_model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	3207777945936 -> 3207778588736
	3207778588736 [label=AccumulateGrad]
	3207778588640 -> 3207778588592
	3207777946096 [label="base_model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	3207777946096 -> 3207778588640
	3207778588640 [label=AccumulateGrad]
	3207778588976 -> 3207778588928
	3207778589312 -> 3207778589600
	3207777946656 [label="base_model.layer3.2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777946656 -> 3207778589312
	3207778589312 [label=AccumulateGrad]
	3207778589552 -> 3207778584320
	3207777946576 [label="base_model.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	3207777946576 -> 3207778589552
	3207778589552 [label=AccumulateGrad]
	3207778589696 -> 3207778584320
	3207777946736 [label="base_model.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	3207777946736 -> 3207778589696
	3207778589696 [label=AccumulateGrad]
	3207778590416 -> 3207778590176
	3207777947296 [label="base_model.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777947296 -> 3207778590416
	3207778590416 [label=AccumulateGrad]
	3207778590128 -> 3207778590560
	3207777947216 [label="base_model.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	3207777947216 -> 3207778590128
	3207778590128 [label=AccumulateGrad]
	3207778590320 -> 3207778590560
	3207777947376 [label="base_model.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	3207777947376 -> 3207778590320
	3207778590320 [label=AccumulateGrad]
	3207778590608 -> 3207778591040
	3207778590848 -> 3207778591184
	3207777947936 [label="base_model.layer3.3.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777947936 -> 3207778590848
	3207778590848 [label=AccumulateGrad]
	3207778591232 -> 3207778591664
	3207777947856 [label="base_model.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	3207777947856 -> 3207778591232
	3207778591232 [label=AccumulateGrad]
	3207778591472 -> 3207778591664
	3207777948016 [label="base_model.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	3207777948016 -> 3207778591472
	3207778591472 [label=AccumulateGrad]
	3207778591376 -> 3207778591856
	3207777948576 [label="base_model.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777948576 -> 3207778591376
	3207778591376 [label=AccumulateGrad]
	3207778592288 -> 3207778592096
	3207777948496 [label="base_model.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	3207777948496 -> 3207778592288
	3207778592288 [label=AccumulateGrad]
	3207778591712 -> 3207778592096
	3207777948656 [label="base_model.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	3207777948656 -> 3207778591712
	3207778591712 [label=AccumulateGrad]
	3207778592048 -> 3207778592000
	3207778592432 -> 3207778592720
	3207777949216 [label="base_model.layer3.4.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777949216 -> 3207778592432
	3207778592432 [label=AccumulateGrad]
	3207778592672 -> 3207778592624
	3207777949136 [label="base_model.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	3207777949136 -> 3207778592672
	3207778592672 [label=AccumulateGrad]
	3207778593056 -> 3207778592624
	3207777949296 [label="base_model.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	3207777949296 -> 3207778593056
	3207778593056 [label=AccumulateGrad]
	3207778593536 -> 3207778593296
	3207777949856 [label="base_model.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777949856 -> 3207778593536
	3207778593536 [label=AccumulateGrad]
	3207778589936 -> 3207778593728
	3207777949776 [label="base_model.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	3207777949776 -> 3207778589936
	3207778589936 [label=AccumulateGrad]
	3207778593248 -> 3207778593728
	3207777949936 [label="base_model.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	3207777949936 -> 3207778593248
	3207778593248 [label=AccumulateGrad]
	3207778594160 -> 3207778593584
	3207778593920 -> 3207778594352
	3207777950496 [label="base_model.layer3.5.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777950496 -> 3207778593920
	3207778593920 [label=AccumulateGrad]
	3207778594784 -> 3207778594208
	3207777950416 [label="base_model.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	3207777950416 -> 3207778594784
	3207778594784 [label=AccumulateGrad]
	3207778594544 -> 3207778594208
	3207777950576 [label="base_model.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	3207777950576 -> 3207778594544
	3207778594544 [label=AccumulateGrad]
	3207778594688 -> 3207778595408
	3207777951136 [label="base_model.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3207777951136 -> 3207778594688
	3207778594688 [label=AccumulateGrad]
	3207778594832 -> 3207778595168
	3207777951056 [label="base_model.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	3207777951056 -> 3207778594832
	3207778594832 [label=AccumulateGrad]
	3207778595216 -> 3207778595168
	3207777951216 [label="base_model.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	3207777951216 -> 3207778595216
	3207778595216 [label=AccumulateGrad]
	3207778595120 -> 3207778595312
	3207778595456 -> 3207778595744
	3207777952496 [label="base_model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	3207777952496 -> 3207778595456
	3207778595456 [label=AccumulateGrad]
	3207778595936 -> 3207778596176
	3207777952416 [label="base_model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	3207777952416 -> 3207778595936
	3207778595936 [label=AccumulateGrad]
	3207778596656 -> 3207778596176
	3207777952576 [label="base_model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	3207777952576 -> 3207778596656
	3207778596656 [label=AccumulateGrad]
	3207778596464 -> 3207778596560
	3207777953136 [label="base_model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3207777953136 -> 3207778596464
	3207778596464 [label=AccumulateGrad]
	3207778596800 -> 3207778597280
	3207777953056 [label="base_model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	3207777953056 -> 3207778596800
	3207778596800 [label=AccumulateGrad]
	3207778596848 -> 3207778597280
	3207777953216 [label="base_model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	3207777953216 -> 3207778596848
	3207778596848 [label=AccumulateGrad]
	3207778597712 -> 3207778597664
	3207778597712 -> 3207778327248 [dir=none]
	3207778327248 [label="input
 (1, 512, 32, 32)" fillcolor=orange]
	3207778597712 -> 3207778240448 [dir=none]
	3207778240448 [label="result1
 (512)" fillcolor=orange]
	3207778597712 -> 3207778253408 [dir=none]
	3207778253408 [label="result2
 (512)" fillcolor=orange]
	3207778597712 -> 3207778246288 [dir=none]
	3207778246288 [label="result3
 (0)" fillcolor=orange]
	3207778597712 -> 3207778297360 [dir=none]
	3207778297360 [label="running_mean
 (512)" fillcolor=orange]
	3207778597712 -> 3207778290080 [dir=none]
	3207778290080 [label="running_var
 (512)" fillcolor=orange]
	3207778597712 -> 3207777951776 [dir=none]
	3207777951776 [label="weight
 (512)" fillcolor=orange]
	3207778597712 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	3207778595840 -> 3207778597712
	3207778595840 -> 3207778328048 [dir=none]
	3207778328048 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778595840 -> 3207777951696 [dir=none]
	3207777951696 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	3207778595840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3207778596032 -> 3207778595840
	3207778595600 -> 3207778595840
	3207777951696 [label="base_model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	3207777951696 -> 3207778595600
	3207778595600 [label=AccumulateGrad]
	3207778596416 -> 3207778597712
	3207777951776 [label="base_model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	3207777951776 -> 3207778596416
	3207778596416 [label=AccumulateGrad]
	3207778596368 -> 3207778597712
	3207777951856 [label="base_model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	3207777951856 -> 3207778596368
	3207778596368 [label=AccumulateGrad]
	3207778597568 -> 3207778597856
	3207777953696 [label="base_model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3207777953696 -> 3207778597568
	3207778597568 [label=AccumulateGrad]
	3207778598336 -> 3207778598288
	3207777953616 [label="base_model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	3207777953616 -> 3207778598336
	3207778598336 [label=AccumulateGrad]
	3207778598192 -> 3207778598288
	3207777953776 [label="base_model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	3207777953776 -> 3207778598192
	3207778598192 [label=AccumulateGrad]
	3207778598096 -> 3207778598864
	3207777954336 [label="base_model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3207777954336 -> 3207778598096
	3207778598096 [label=AccumulateGrad]
	3207778598816 -> 3207778598720
	3207777954256 [label="base_model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	3207777954256 -> 3207778598816
	3207778598816 [label=AccumulateGrad]
	3207778598768 -> 3207778598720
	3207777954416 [label="base_model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	3207777954416 -> 3207778598768
	3207778598768 [label=AccumulateGrad]
	3207778598048 -> 3207778582736
	3207778582928 -> 3207778583888
	3207777954976 [label="base_model.layer4.2.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3207777954976 -> 3207778582928
	3207778582928 [label=AccumulateGrad]
	3207778583840 -> 3207778584176
	3207777954896 [label="base_model.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	3207777954896 -> 3207778583840
	3207778583840 [label=AccumulateGrad]
	3207778584512 -> 3207778584176
	3207777955056 [label="base_model.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	3207777955056 -> 3207778584512
	3207778584512 [label=AccumulateGrad]
	3207778584800 -> 3207778585088
	3207777955616 [label="base_model.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3207777955616 -> 3207778584800
	3207778584800 [label=AccumulateGrad]
	3207778585424 -> 3207778585760
	3207777955536 [label="base_model.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	3207777955536 -> 3207778585424
	3207778585424 [label=AccumulateGrad]
	3207778585376 -> 3207778585760
	3207777955696 [label="base_model.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	3207777955696 -> 3207778585376
	3207778585376 [label=AccumulateGrad]
	3207778585712 -> 3207778586048
	3207778586624 -> 3207778587008
	3207778252528 [label="layer4_1x1.0.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	3207778252528 -> 3207778586624
	3207778586624 [label=AccumulateGrad]
	3207778587632 -> 3207778587008
	3207778252448 [label="layer4_1x1.0.bias
 (512)" fillcolor=lightblue]
	3207778252448 -> 3207778587632
	3207778587632 [label=AccumulateGrad]
	3207778587920 -> 3207778588208
	3207778587920 -> 3207674265040 [dir=none]
	3207674265040 [label="result
 (1, 256, 64, 64)" fillcolor=orange]
	3207778587920 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778586336 -> 3207778587920
	3207778586336 -> 3207778328048 [dir=none]
	3207778328048 [label="input
 (1, 256, 64, 64)" fillcolor=orange]
	3207778586336 -> 3207778253168 [dir=none]
	3207778253168 [label="weight
 (256, 256, 1, 1)" fillcolor=orange]
	3207778586336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778596032 -> 3207778586336
	3207778586384 -> 3207778586336
	3207778253168 [label="layer3_1x1.0.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	3207778253168 -> 3207778586384
	3207778586384 [label=AccumulateGrad]
	3207778586000 -> 3207778586336
	3207778252928 [label="layer3_1x1.0.bias
 (256)" fillcolor=lightblue]
	3207778252928 -> 3207778586000
	3207778586000 [label=AccumulateGrad]
	3207778588544 -> 3207778588496
	3207778252048 [label="conv_up3.0.weight
 (512, 768, 3, 3)" fillcolor=lightblue]
	3207778252048 -> 3207778588544
	3207778588544 [label=AccumulateGrad]
	3207778589120 -> 3207778588496
	3207778251968 [label="conv_up3.0.bias
 (512)" fillcolor=lightblue]
	3207778251968 -> 3207778589120
	3207778589120 [label=AccumulateGrad]
	3207778589456 -> 3207778590080
	3207778589456 -> 3207674262560 [dir=none]
	3207674262560 [label="result
 (1, 128, 128, 128)" fillcolor=orange]
	3207778589456 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778588256 -> 3207778589456
	3207778588256 -> 3207777955776 [dir=none]
	3207777955776 [label="input
 (1, 128, 128, 128)" fillcolor=orange]
	3207778588256 -> 3207778253648 [dir=none]
	3207778253648 [label="weight
 (128, 128, 1, 1)" fillcolor=orange]
	3207778588256 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (128,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778585952 -> 3207778588256
	3207778586960 -> 3207778588256
	3207778253648 [label="layer2_1x1.0.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	3207778253648 -> 3207778586960
	3207778586960 [label=AccumulateGrad]
	3207778587872 -> 3207778588256
	3207778253568 [label="layer2_1x1.0.bias
 (128)" fillcolor=lightblue]
	3207778253568 -> 3207778587872
	3207778587872 [label=AccumulateGrad]
	3207778590032 -> 3207778590368
	3207778251568 [label="conv_up2.0.weight
 (256, 640, 3, 3)" fillcolor=lightblue]
	3207778251568 -> 3207778590032
	3207778590032 [label=AccumulateGrad]
	3207778590992 -> 3207778590368
	3207778251248 [label="conv_up2.0.bias
 (256)" fillcolor=lightblue]
	3207778251248 -> 3207778590992
	3207778590992 [label=AccumulateGrad]
	3207778591328 -> 3207778590512
	3207778591328 -> 3207778242048 [dir=none]
	3207778242048 [label="result
 (1, 64, 256, 256)" fillcolor=orange]
	3207778591328 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778589744 -> 3207778591328
	3207778589744 -> 3207777952656 [dir=none]
	3207777952656 [label="input
 (1, 64, 256, 256)" fillcolor=orange]
	3207778589744 -> 3207778254448 [dir=none]
	3207778254448 [label="weight
 (64, 64, 1, 1)" fillcolor=orange]
	3207778589744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778541456 -> 3207778589744
	3207778588880 -> 3207778589744
	3207778254448 [label="layer1_1x1.0.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	3207778254448 -> 3207778588880
	3207778588880 [label=AccumulateGrad]
	3207778589792 -> 3207778589744
	3207778254048 [label="layer1_1x1.0.bias
 (64)" fillcolor=lightblue]
	3207778254048 -> 3207778589792
	3207778589792 [label=AccumulateGrad]
	3207778591952 -> 3207778591904
	3207778250928 [label="conv_up1.0.weight
 (256, 320, 3, 3)" fillcolor=lightblue]
	3207778250928 -> 3207778591952
	3207778591952 [label=AccumulateGrad]
	3207778592528 -> 3207778591904
	3207778250848 [label="conv_up1.0.bias
 (256)" fillcolor=lightblue]
	3207778250848 -> 3207778592528
	3207778592528 [label=AccumulateGrad]
	3207778591760 -> 3207778593488
	3207778591760 -> 3207778250208 [dir=none]
	3207778250208 [label="result
 (1, 64, 512, 512)" fillcolor=orange]
	3207778591760 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778591616 -> 3207778591760
	3207778591616 -> 3207777950016 [dir=none]
	3207777950016 [label="input
 (1, 64, 512, 512)" fillcolor=orange]
	3207778591616 -> 3207778242128 [dir=none]
	3207778242128 [label="weight
 (64, 64, 1, 1)" fillcolor=orange]
	3207778591616 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778549376 -> 3207778591616
	3207778589264 -> 3207778591616
	3207778242128 [label="layer0_1x1.0.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	3207778242128 -> 3207778589264
	3207778589264 [label=AccumulateGrad]
	3207778591280 -> 3207778591616
	3207778254768 [label="layer0_1x1.0.bias
 (64)" fillcolor=lightblue]
	3207778254768 -> 3207778591280
	3207778591280 [label=AccumulateGrad]
	3207778592384 -> 3207778593824
	3207778250448 [label="conv_up0.0.weight
 (128, 320, 3, 3)" fillcolor=lightblue]
	3207778250448 -> 3207778592384
	3207778592384 [label=AccumulateGrad]
	3207778594448 -> 3207778593824
	3207778250048 [label="conv_up0.0.bias
 (128)" fillcolor=lightblue]
	3207778250048 -> 3207778594448
	3207778594448 [label=AccumulateGrad]
	3207778594736 -> 3207778595024
	3207778594736 -> 3207778249488 [dir=none]
	3207778249488 [label="result
 (1, 64, 1024, 1024)" fillcolor=orange]
	3207778594736 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778593152 -> 3207778594736
	3207778593152 -> 3207777948976 [dir=none]
	3207777948976 [label="input
 (1, 64, 1024, 1024)" fillcolor=orange]
	3207778593152 -> 3207778249008 [dir=none]
	3207778249008 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3207778593152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778592240 -> 3207778593152
	3207778592240 -> 3207778238928 [dir=none]
	3207778238928 [label="result
 (1, 64, 1024, 1024)" fillcolor=orange]
	3207778592240 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3207778587248 -> 3207778592240
	3207778587248 -> 3207777946256 [dir=none]
	3207777946256 [label="input
 (1, 3, 1024, 1024)" fillcolor=orange]
	3207778587248 -> 3207778249648 [dir=none]
	3207778249648 [label="weight
 (64, 3, 3, 3)" fillcolor=orange]
	3207778587248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3207778584752 -> 3207778587248
	3207778249648 [label="conv_original_size0.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	3207778249648 -> 3207778584752
	3207778584752 [label=AccumulateGrad]
	3207778585136 -> 3207778587248
	3207778249568 [label="conv_original_size0.0.bias
 (64)" fillcolor=lightblue]
	3207778249568 -> 3207778585136
	3207778585136 [label=AccumulateGrad]
	3207778593200 -> 3207778593152
	3207778249008 [label="conv_original_size1.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3207778249008 -> 3207778593200
	3207778593200 [label=AccumulateGrad]
	3207778593008 -> 3207778593152
	3207778248928 [label="conv_original_size1.0.bias
 (64)" fillcolor=lightblue]
	3207778248928 -> 3207778593008
	3207778593008 [label=AccumulateGrad]
	3207778595360 -> 3207778596320
	3207778248528 [label="conv_original_size2.0.weight
 (64, 192, 3, 3)" fillcolor=lightblue]
	3207778248528 -> 3207778595360
	3207778595360 [label=AccumulateGrad]
	3207778594880 -> 3207778596320
	3207778248128 [label="conv_original_size2.0.bias
 (64)" fillcolor=lightblue]
	3207778248128 -> 3207778594880
	3207778594880 [label=AccumulateGrad]
	3207778595984 -> 3207778596608
	3207778247728 [label="conv_last.weight
 (2, 64, 1, 1)" fillcolor=lightblue]
	3207778247728 -> 3207778595984
	3207778595984 [label=AccumulateGrad]
	3207778595648 -> 3207778596608
	3207778247648 [label="conv_last.bias
 (2)" fillcolor=lightblue]
	3207778247648 -> 3207778595648
	3207778595648 [label=AccumulateGrad]
	3207778596608 -> 3207777947696
}
